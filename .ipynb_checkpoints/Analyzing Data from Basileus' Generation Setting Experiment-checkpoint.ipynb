{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17a6c451",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Analyzing-Data-from-Basileus'-Generation-Setting-Experiment\" data-toc-modified-id=\"Analyzing-Data-from-Basileus'-Generation-Setting-Experiment-1\">Analyzing Data from Basileus' Generation Setting Experiment</a></span><ul class=\"toc-item\"><li><span><a href=\"#Variables-in-the-dataset\" data-toc-modified-id=\"Variables-in-the-dataset-1.1\">Variables in the dataset</a></span></li><li><span><a href=\"#Reading-in-the-data\" data-toc-modified-id=\"Reading-in-the-data-1.2\">Reading in the data</a></span></li><li><span><a href=\"#Visual-data-inspection\" data-toc-modified-id=\"Visual-data-inspection-1.3\">Visual data inspection</a></span><ul class=\"toc-item\"><li><span><a href=\"#Distribution-of-target-variables\" data-toc-modified-id=\"Distribution-of-target-variables-1.3.1\">Distribution of target variables</a></span></li><li><span><a href=\"#Relationships-between-variables\" data-toc-modified-id=\"Relationships-between-variables-1.3.2\">Relationships between variables</a></span></li></ul></li><li><span><a href=\"#Correlations\" data-toc-modified-id=\"Correlations-1.4\">Correlations</a></span></li><li><span><a href=\"#Regression-Analysis\" data-toc-modified-id=\"Regression-Analysis-1.5\">Regression Analysis</a></span><ul class=\"toc-item\"><li><span><a href=\"#Randomness-predicting-Grammar/Style/Spelling\" data-toc-modified-id=\"Randomness-predicting-Grammar/Style/Spelling-1.5.1\">Randomness predicting Grammar/Style/Spelling</a></span></li><li><span><a href=\"#Randomness-predicting-Readability-Grade\" data-toc-modified-id=\"Randomness-predicting-Readability-Grade-1.5.2\">Randomness predicting Readability Grade</a></span><ul class=\"toc-item\"><li><span><a href=\"#Regression-diagnostics-(checking-assumptions)\" data-toc-modified-id=\"Regression-diagnostics-(checking-assumptions)-1.5.2.1\">Regression diagnostics (checking assumptions)</a></span></li></ul></li><li><span><a href=\"#Presentation-of-Regression\" data-toc-modified-id=\"Presentation-of-Regression-1.5.3\">Presentation of Regression</a></span><ul class=\"toc-item\"><li><span><a href=\"#Plotting-the-relationships\" data-toc-modified-id=\"Plotting-the-relationships-1.5.3.1\">Plotting the relationships</a></span></li></ul></li><li><span><a href=\"#Randomness-predicting-Glue-Index\" data-toc-modified-id=\"Randomness-predicting-Glue-Index-1.5.4\">Randomness predicting Glue Index</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e55df65",
   "metadata": {},
   "source": [
    "# Analyzing Data from Basileus' Generation Setting Experiment\n",
    "\n",
    "*Put stuff here explaining on the methodology (\"what was done\")...*\n",
    "\n",
    "Data can be obtained [here](https://docs.google.com/spreadsheets/d/1a-oHJdBUvwTUam7Y9U9vqEvrcd4fK2q3oqm3H4iI4G0/edit#gid=116999801)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7076a8",
   "metadata": {},
   "source": [
    "## Variables in the dataset\n",
    "\n",
    "Variable|Meaning|Target\n",
    "-|-|-\n",
    "Randomness|Generator Setting|Independent Variable\n",
    "Tail-Free|Generator Setting|Independent Variable\n",
    "Grammar/Style/Spelling|Your writing can have no spelling or grammar mistakes but still be awkward, clumsy, and hard to read. Style can make your writing easier and more enjoyable to read. Style covers issues like repeated sentence starts, clunky word order and phrasing, hidden verbs, and more.|Higher is better\n",
    "Readability Grade|A readability score is a measure of how easy your text is to read. Your readability score shows what grade level of students could understand and engage with your writing. For instance, a score of 7 means that seventh-grade students could read your work.|Lower is better\n",
    "Glue Index|Glue words are words that are common, low-quality, or nondescript, and too many of them can make your sentences \"sticky\". Sticky sentences slow your reader down; try to avoid them.|Lower is better"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafa97c5",
   "metadata": {},
   "source": [
    "## Reading in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ecbf25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from sklearn.preprocessing import PolynomialFeatures as polyfeat\n",
    "from sklearn.linear_model import LinearRegression as linreg\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.model_selection import cross_validate, KFold\n",
    "\n",
    "# Read in data of the GSheet document\n",
    "nai_rand_only = pd.read_csv(\n",
    "    'https://docs.google.com/spreadsheets/d/1a-oHJdBUvwTUam7Y9U9vqEvrcd4fK2q3oqm3H4iI4G0/export?format=csv&gid=1831608934', header=1)\n",
    "\n",
    "nai_rand_tfs = pd.read_csv(\n",
    "    'https://docs.google.com/spreadsheets/d/1a-oHJdBUvwTUam7Y9U9vqEvrcd4fK2q3oqm3H4iI4G0/export?format=csv&gid=832120712', header=1)\n",
    "\n",
    "print(\"First 3 lines of nai_rand_only:\\n\")\n",
    "print(nai_rand_only.iloc[:, :15].head(3))\n",
    "print(nai_rand_only.iloc[:, 15:].head(3))\n",
    "\n",
    "\n",
    "print(\"\\nFirst 3 lines of nai_rand_tfs:\\n\")\n",
    "print(nai_rand_tfs.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a457939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nai_rand_only has a few instances of the double quote bug. These have been removed for nai_rand_tfs since they tank some rating scores.\n",
    "# To keep things consistent, we will remove them for nai_rand_only as well\n",
    "mask = nai_rand_only[\"Raw\"].str.contains('\\S\"\\S', regex=True)\n",
    "nai_rand_only = nai_rand_only[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b2524f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Combine datasets\n",
    "nai = nai_rand_only.append(nai_rand_tfs)\n",
    "\n",
    "print(\"\\nFirst three lines of data:\\n\")\n",
    "print(nai.iloc[:, :15].head(3))\n",
    "print(nai.iloc[:, 15:].head(3))\n",
    "\n",
    "print(\"\\nLast three lines of data:\\n\")\n",
    "print(nai.iloc[:, :15].tail(3))\n",
    "print(nai.iloc[:, 15:].tail(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d189f496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns without data (and data without variance)\n",
    "nai = nai[[\"Randomness\", \"Tail-Free\", \"Nucleus\",\n",
    "           \"Grammar/Style/Spelling\", \"Readability Grade\", \"Glue Index\",\n",
    "          \"Raw\"]]\n",
    "\n",
    "print(\"\\nFirst three lines of data:\\n\")\n",
    "print(nai.iloc[:, :15].head(3))\n",
    "print(nai.iloc[:, 15:].head(3))\n",
    "\n",
    "print(\"\\nLast three lines of data:\\n\")\n",
    "print(nai.iloc[:, :15].tail(3))\n",
    "print(nai.iloc[:, 15:].tail(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f51e4c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convert \"disabled\" for tail free to \"1\"\n",
    "nai[\"Tail-Free\"] = nai[\"Tail-Free\"].replace({\"disabled\": \"1\"}).astype(float)\n",
    "\n",
    "# Convert NaN for Nucelus to \"1\"\n",
    "nai[\"Nucleus\"].fillna(1, inplace = True)\n",
    "\n",
    "# Convert % strings to float\n",
    "nai[[\"Grammar/Style/Spelling\", \"Glue Index\"]] = nai[[\"Grammar/Style/Spelling\",\n",
    "                                                     \"Glue Index\"]].astype(str).replace({\"\\%\": \"\"}, regex=True).astype(float)\n",
    "\n",
    "print(\"\\nFirst three lines of data:\\n\")\n",
    "print(nai.iloc[:, :15].head(3))\n",
    "print(nai.iloc[:, 15:].head(3))\n",
    "\n",
    "print(\"\\nLast three lines of data:\\n\")\n",
    "print(nai.iloc[:, :15].tail(3))\n",
    "print(nai.iloc[:, 15:].tail(3))\n",
    "\n",
    "nai.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e35ec83",
   "metadata": {},
   "source": [
    "## Visual data inspection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fcbb20",
   "metadata": {},
   "source": [
    "### Distribution of target variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b12fdd6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "fig, axes = plt.subplots(3, 2, figsize=(10, 10))\n",
    "\n",
    "# Histograms with KDE\n",
    "ax1 = nai[\"Grammar/Style/Spelling\"].plot.hist(ax=axes[0, 0], bins=15)\n",
    "ax1.set_xlabel(\"Grammar/Style/Spelling\")\n",
    "nai[\"Grammar/Style/Spelling\"].plot.kde(ax=axes[0, 0], secondary_y=True)\n",
    "\n",
    "ax2 = nai[\"Readability Grade\"].plot.hist(ax=axes[1, 0], bins=15)\n",
    "ax2.set_xlabel(\"Readability Grade\")\n",
    "nai[\"Readability Grade\"].plot.kde(ax=axes[1, 0], secondary_y=True)\n",
    "\n",
    "ax3 = nai[\"Glue Index\"].plot.hist(ax=axes[2, 0], bins=15)\n",
    "nai[\"Glue Index\"].plot.kde(ax=axes[2, 0], secondary_y=True)\n",
    "ax3.set_xlabel(\"Glue Index\")\n",
    "\n",
    "\n",
    "# Boxplots\n",
    "nai[\"Grammar/Style/Spelling\"].plot.box(ax=axes[0, 1])\n",
    "nai[\"Readability Grade\"].plot.box(ax=axes[1, 1])\n",
    "nai[\"Glue Index\"].plot.box(ax=axes[2, 1])\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d387bdf",
   "metadata": {},
   "source": [
    "We have a few minor outliers, but nothing too much out of the ordinary that sticks out. I also would be hesitant to remove any outlier for analysis, since we in this case we can be sure, that all data points are truly part of the \"population\" (i.e. all potential outputs that we could have gotten with the respective setting)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eff1f45",
   "metadata": {},
   "source": [
    "### Relationships between variables\n",
    "\n",
    "A few scatter plot with lowess lines to see if we are dealing with linear relationships. I'd actually expect something more like a curvilinear relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f44839b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "fig, axes = plt.subplots(4, 3, figsize=(15, 15))\n",
    "plt.grid(False)\n",
    "# Relationship with Randomness\n",
    "sns.regplot(data=nai, y=\"Grammar/Style/Spelling\",\n",
    "            x=\"Randomness\", lowess=True, ax=axes[0, 0])\n",
    "sns.regplot(data=nai, y=\"Readability Grade\",\n",
    "            x=\"Randomness\", lowess=True, ax=axes[0, 1])\n",
    "sns.regplot(data=nai, y=\"Glue Index\", x=\"Randomness\",\n",
    "            lowess=True, ax=axes[0, 2])\n",
    "# Relationships with TFS\n",
    "sns.regplot(data=nai, y=\"Grammar/Style/Spelling\",\n",
    "            x=\"Tail-Free\", lowess=True, ax=axes[1, 0])\n",
    "sns.regplot(data=nai, y=\"Readability Grade\",\n",
    "            x=\"Tail-Free\", lowess=True, ax=axes[1, 1])\n",
    "sns.regplot(data=nai, y=\"Glue Index\", x=\"Tail-Free\",\n",
    "            lowess=True, ax=axes[1, 2])\n",
    "# Relationships with Nucleus (not much here yet since only 0.9 or 1.0)\n",
    "sns.barplot(data=nai, y=\"Grammar/Style/Spelling\",\n",
    "            x=\"Nucleus\", ax=axes[2, 0])\n",
    "sns.barplot(data=nai, y=\"Readability Grade\",\n",
    "            x=\"Nucleus\", ax=axes[2, 1])\n",
    "sns.barplot(data=nai, y=\"Glue Index\", x=\"Nucleus\",\n",
    "            ax=axes[2, 2])\n",
    "# Relationships between dependent vars\n",
    "sns.regplot(data=nai, y=\"Grammar/Style/Spelling\",\n",
    "            x=\"Readability Grade\", lowess=False, ax=axes[3, 0])\n",
    "sns.regplot(data=nai, y=\"Grammar/Style/Spelling\",\n",
    "            x=\"Glue Index\", lowess=False, ax=axes[3, 1])\n",
    "sns.regplot(data=nai, y=\"Readability Grade\",\n",
    "            x=\"Glue Index\", lowess=False, ax=axes[3, 2])\n",
    "\n",
    "for ax in fig.axes:\n",
    "    ax.grid(False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf6569b",
   "metadata": {},
   "source": [
    "**(The following bit is outdated and only applies to random without tail-free. I will revise this once we have all the data)**\n",
    "Hmm interesting, the relationship with Grammar/Style/Spelling looks like a weak quadratic relationship (\"reverse U\"), with Readability it looks a little bit cubic (but a linear relationship might be a decent enough fit with less danger of overfitting), and Glue Index might be *more or less* quadratic.\n",
    "\n",
    "There seems to be not much reliable relationship of any kind between the target variables (will still be looking at correlations below), so a MANOVA (which depends on a linear combination of the dependent variables) is probably out of the question."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a3ccf0",
   "metadata": {},
   "source": [
    "## Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcca8e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "nai[[\"Randomness\", \"Tail-Free\", \"Nucleus\", \"Grammar/Style/Spelling\",\n",
    "     \"Readability Grade\", \"Glue Index\"]].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc5b902",
   "metadata": {},
   "source": [
    "**(The following bit is outdated and only applies to random without tail-free. I will revise this once we have all the data)**\n",
    "Best to ignore the results for correlations Randomness <-> Grammar/Style/Spelling and Randomness <-> Glue Index, since the relationship clearly is non-linear.\n",
    "\n",
    "Otherwise:\n",
    "* Strong negative linear relations between Readability and Randomness (lower is better for readability) so: the higher the randomness, the worse readability tends to be)\n",
    "* The 3 target variables really have weak to none linear relationships with each other"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0871c7e4",
   "metadata": {},
   "source": [
    "## Regression Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019f17ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows without values for the dependent vars, can be deleted later if all the data is in\n",
    "nai.dropna(subset=[\"Grammar/Style/Spelling\",\n",
    "                   \"Readability Grade\", \"Glue Index\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d48a6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up k-fold cross validation\n",
    "\n",
    "kf = KFold(10, shuffle=True, random_state=42)\n",
    "\n",
    "# Defining predictors for models\n",
    "nai[\"Rand_cent\"] = nai[\"Randomness\"].apply(\n",
    "    lambda x: x-nai[\"Randomness\"].mean())  # centering\n",
    "nai[\"TFS_cent\"] = nai[\"Tail-Free\"].apply(lambda x: x-nai[\"Tail-Free\"].mean())\n",
    "nai[\"Nuc_cent\"] = nai[\"Nucleus\"].apply(lambda x: x-nai[\"Nucleus\"].mean())\n",
    "predictors = nai[[\"Rand_cent\", \"TFS_cent\", \"Nuc_cent\"]]\n",
    "\n",
    "# to include interaction\n",
    "poly_lin = polyfeat(interaction_only=True, include_bias=False)\n",
    "lin_predictors = poly_lin.fit_transform(predictors)\n",
    "poly_quad = polyfeat(degree=2, include_bias=False)\n",
    "quad_predictors = poly_quad.fit_transform(predictors)\n",
    "poly_cub = polyfeat(degree=3, include_bias=False)\n",
    "cub_predictors = poly_cub.fit_transform(predictors)\n",
    "# poly_quart = polyfeat(degree=4, include_bias=False)\n",
    "# quart_predictors = poly_quart.fit_transform(predictors)\n",
    "# poly_quint = polyfeat(degree=5, include_bias=False)\n",
    "# quint_predictors = poly_quint.fit_transform(predictors)\n",
    "\n",
    "# Display created feature names\n",
    "print(\"Linear features:\")\n",
    "print(poly_lin.get_feature_names(predictors.columns))\n",
    "print(\"\\nQuadratic features:\")\n",
    "print(poly_quad.get_feature_names(predictors.columns))\n",
    "print(\"\\nCubic features:\")\n",
    "print(poly_cub.get_feature_names(predictors.columns))\n",
    "# print(\"\\nQuartic features:\")\n",
    "# print(poly_quart.get_feature_names(predictors.columns))\n",
    "# print(\"\\nQuintic features:\")\n",
    "# print(poly_quint.get_feature_names(predictors.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184c7988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We do not need interactions between TFS x Nucleus, so we are removing those\n",
    "# Also removing poly terms for Nucleus (should be kept once we have more data for Nucleus)\n",
    "lin_predictors = np.delete(lin_predictors, 5, axis = 1)\n",
    "quad_predictors = np.delete(quad_predictors, np.s_[7:], axis = 1)\n",
    "# Quite a lot of features to remove for cubic - working from the back of the array...\n",
    "cub_predictors = np.delete(cub_predictors, np.s_[16:], axis = 1) # remove TFS x Nucleus poly ints and Nucleus**3\n",
    "cub_predictors = np.delete(cub_predictors, np.s_[13, 14], axis = 1) # remove Rand x TFS x Nucleus and Rand x Nucleus**2\n",
    "cub_predictors = np.delete(cub_predictors, np.s_[7:9], axis = 1) # remove TFS x Nucleus and Nucleus ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d1a20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup scikit linear model\n",
    "lin_model = linreg()\n",
    "\n",
    "# setup list of model names with predictor arrays\n",
    "predictor_li = [(\"linear\", lin_predictors), (\"quadratic\", quad_predictors),\n",
    "                (\"cubic\", cub_predictors)]\n",
    "# predictor_li = [(\"linear\", lin_predictors), (\"quadratic\", quad_predictors),\n",
    "#                 (\"cubic\", cub_predictors), (\"quartic\", quart_predictors), (\"quintic\", quint_predictors)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b6d838",
   "metadata": {},
   "source": [
    "### Randomness predicting Grammar/Style/Spelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0050f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select best model\n",
    "for pred in predictor_li:\n",
    "    current_pred = pred[1]\n",
    "    current_model_name = pred[0]\n",
    "    cross_val = cross_validate(lin_model, current_pred, nai[\"Grammar/Style/Spelling\"],\n",
    "                               scoring=[\"neg_mean_squared_error\", \"r2\"], cv=kf)\n",
    "    neg_mses = cross_val[\"test_neg_mean_squared_error\"]\n",
    "    r_squares = cross_val[\"test_r2\"]\n",
    "    avg_rmse = np.mean((neg_mses*-1)**0.5)\n",
    "    avg_r_sq = np.mean(r_squares)\n",
    "    print(\"Model performance for {} model predicting Grammar/Style/Spelling:\".format(current_model_name))\n",
    "    print(\"r-square: {:.4f}    RMSE: {:.2f}\\n\".format(avg_r_sq, avg_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3321f9b8",
   "metadata": {},
   "source": [
    "These model performances are all so terrible, that I would not bother to investigate further - there might be a *very small* relationship here (our sample is quite big), but it is too small to really matter in practice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc025adf",
   "metadata": {},
   "source": [
    "### Randomness predicting Readability Grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdc94d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select best model\n",
    "for pred in predictor_li:\n",
    "    current_pred = pred[1]\n",
    "    current_model_name = pred[0]\n",
    "    cross_val = cross_validate(lin_model, current_pred, nai[\"Readability Grade\"],\n",
    "                               scoring=[\"neg_mean_squared_error\", \"r2\"], cv=kf)\n",
    "    neg_mses = cross_val[\"test_neg_mean_squared_error\"]\n",
    "    r_squares = cross_val[\"test_r2\"]\n",
    "    avg_rmse = np.mean((neg_mses*-1)**0.5)\n",
    "    avg_r_sq = np.mean(r_squares)\n",
    "    print(\"Model performance for {} model predicting Readability:\".format(\n",
    "        current_model_name))\n",
    "    print(\"r-square: {:.4f}    RMSE: {:.2f}\\n\".format(avg_r_sq, avg_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e8209b",
   "metadata": {},
   "source": [
    "This looks more promising, continuing with quadratic model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c569204",
   "metadata": {},
   "source": [
    "#### Regression diagnostics (checking assumptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d617ba75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fit model and save residuals\n",
    "lin_model.fit(quad_predictors, nai[\"Readability Grade\"])\n",
    "\n",
    "pred = lin_model.predict(quad_predictors)\n",
    "obs_pred_res_df = pd.DataFrame(\n",
    "    {'Actual': nai[\"Readability Grade\"], 'Predicted': pred})\n",
    "obs_pred_res_df[\"Residuals\"] = obs_pred_res_df['Actual'] - \\\n",
    "    obs_pred_res_df['Predicted']\n",
    "\n",
    "# Check for normal distribution of residuals with histogram and Q-Q plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Histograms with KDE\n",
    "ax1 = obs_pred_res_df[\"Residuals\"].plot.hist(ax=axes[0], bins=15)\n",
    "ax1.set_xlabel(\"Regression Residuals\")\n",
    "obs_pred_res_df[\"Residuals\"].plot.kde(ax=axes[0], secondary_y=True)\n",
    "# Q-Q Plot\n",
    "stats.probplot(obs_pred_res_df[\"Residuals\"], dist=\"norm\", plot=axes[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622b0c15",
   "metadata": {},
   "source": [
    "Residuals are (approximately) normally distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6d7aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for Homoscedasticity\n",
    "\n",
    "plot = obs_pred_res_df.plot.scatter(x=\"Predicted\", y=\"Residuals\")\n",
    "#horiz_line_data = np.array([40 for i in xrange(len(xs))])\n",
    "plt.axhline(y=0, linestyle='-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d47c37",
   "metadata": {},
   "source": [
    "Residuals seem close enough to homoscedacity - looks like assumptions for a linear regression hold!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93e1fc4",
   "metadata": {},
   "source": [
    "### Presentation of Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a75ba1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "model = smf.ols(\n",
    "    data=nai, formula=\"Q('Readability Grade') ~ Rand_cent + I(Rand_cent**2) + \\\n",
    "    TFS_cent + I(TFS_cent**2) + \\\n",
    "    Nuc_cent + \\\n",
    "    Rand_cent:TFS_cent + Rand_cent:Nuc_cent\")\n",
    "\n",
    "# the names for the predictors are getting tedious to read, so setting up custom names\n",
    "x_names = [\"Intercept\",\n",
    "           \"Randomness\", \"Randomness**2\",\n",
    "           \"TF-Sampling\", \"TF-Sampling**2\",\n",
    "           \"Nucleus Sampling\",\n",
    "           \"Randomness x TF-Sampling\", \"Randomness x Nucleus Sampling\"]\n",
    "\n",
    "res = model.fit()\n",
    "print(\"Cubic Model Predicting Readability with CENTERED (!) Predcitors\\n\")\n",
    "# print(res.summary())\n",
    "print(res.summary(xname=x_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda1b5b4",
   "metadata": {},
   "source": [
    "**THIS IS ALSO OUTDATED WILL BE UPDATED LATER**\n",
    "\n",
    "The randomness settings explains a whooping 30% of the variation of the Readability Grade. \n",
    "\n",
    "Remember, that the readability represents \"what grade level of students could understand and engage with your writing. For instance, a score of 7 means that seventh-grade students could read your work.\". \n",
    "\n",
    "A *lower* readability score is thus better (although arguably if it gets *too* low, the style might become a bit \"primitive\"? The formula for the expected readability *with everything on default setting* is:\n",
    "\n",
    "Readability Grade = 0.34 + (7.1 * Randomness Setting)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a14fb0",
   "metadata": {},
   "source": [
    "#### Plotting the relationships\n",
    "For now, I will be plotting a line with predicted values for TFS = 1 (no sampling), 0.9, 0.8, 0.7, 0.6, 0.5) and randomness values with 0.05 steps (but it should stay in the range we have data for)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e25f7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfs_plot_values = [1, 0.9, 0.8, 0.7, 0.6, 0.5, 0.4]\n",
    "rand_plot_values = np.arange(0.1, 1.0, 0.05)\n",
    "nucleus_plot_values = [1, 0.9] # not used for now\n",
    "\n",
    "# Construct dataframe with values to predict (all in one graph)\n",
    "pred_df = pd.DataFrame()\n",
    "\n",
    "for tfs_val in tfs_plot_values:\n",
    "    # The regression used centered values so we need to transform tfs_val as well\n",
    "    tfs_val_cent = tfs_val - nai[\"Tail-Free\"].mean()\n",
    "    # When tfs is off (1), graph for nucleus sampling = 0.9\n",
    "    if tfs_val == 1:\n",
    "        nucleus_val = 0.9\n",
    "    else:\n",
    "        nucleus_val = 1\n",
    "    nuc_val_cent = 0.9 - nai[\"Nucleus\"].mean()\n",
    "\n",
    "    # determine range of data for current Nucleus\n",
    "    mask = (nai[\"Nucleus\"] == nucleus_val) & (nai[\"Tail-Free\"] == tfs_val)\n",
    "    rand_min = nai[mask][\"Randomness\"].min()\n",
    "    rand_max = nai[mask][\"Randomness\"].max()\n",
    "\n",
    "    current_rand_range = np.arange(rand_min, rand_max+0.05, 0.05)\n",
    "    current_rand_range_cent = current_rand_range - nai[\"Randomness\"].mean()\n",
    "\n",
    "    current_pred_df = pd.DataFrame(\n",
    "        {\"const\": 1, \"Randomness\": current_rand_range, \"Tail-Free Sampling\": tfs_val, \"Nucleus\": nucleus_val,\n",
    "         \"Rand_cent\": current_rand_range_cent, \"TFS_cent\":tfs_val_cent, \"Nuc_cent\": nuc_val_cent})\n",
    "    pred_df = pred_df.append(current_pred_df, ignore_index = True)\n",
    "\n",
    "# Add predicted readability to table constructed above\n",
    "pred_df[\"Predicted Readbility\"] = res.predict(pred_df[[\"const\", \"Rand_cent\", \"TFS_cent\", \"Nuc_cent\"]])\n",
    "\n",
    "# replace Tail-Free Sampling 1 with \"No TFS (NS = 0.9)\"\n",
    "pred_df[\"Tail-Free Sampling\"].replace(1, \"No TFS (NS = 0.9)\", inplace = True)\n",
    "\n",
    "print(pred_df[[\"Randomness\", \"Tail-Free Sampling\", \"Nucleus\", \"Predicted Readbility\"]].head(10))\n",
    "\n",
    "# Dataframe for displaying main effect of TFS only\n",
    "tfs_only_plot_values = [0.9, 0.8, 0.7, 0.6, 0.5, 0.4]\n",
    "\n",
    "pred_tfs_only_df = pd.DataFrame()\n",
    "\n",
    "for tfs_val in tfs_only_plot_values:\n",
    "    # The regression used centered values so we need to transform tfs_val as well\n",
    "    tfs_val_cent = tfs_val - nai[\"Tail-Free\"].mean()\n",
    "    # Only plotting for tfs so nucleus is off (=1)\n",
    "    nuc_val_cent = 1 - nai[\"Nucleus\"].mean()\n",
    "    # Plot for average randomness\n",
    "    rand_val_cent = 0\n",
    "    \n",
    "    current_pred_dict = (\n",
    "        {\"const\": 1, \"Tail-Free Sampling\": tfs_val,\n",
    "         \"Rand_cent\": rand_val_cent, \"TFS_cent\":tfs_val_cent, \"Nuc_cent\": nuc_val_cent})\n",
    "    pred_tfs_only_df = pred_tfs_only_df.append(current_pred_dict, ignore_index = True)\n",
    "\n",
    "# Add predicted readability to table constructed above\n",
    "pred_tfs_only_df[\"Predicted Readbility\"] = res.predict(pred_tfs_only_df[[\"const\", \"Rand_cent\", \"TFS_cent\", \"Nuc_cent\"]])\n",
    "\n",
    "print(pred_tfs_only_df[[\"Tail-Free Sampling\", \"Predicted Readbility\"]].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c90a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "hue_order_lm = [\"No TFS (NS = 0.9)\", 0.9, 0.8, 0.7, 0.6, 0.5, 0.4]\n",
    "hue_order_scatter = [1, 0.9, 0.8, 0.7, 0.6, 0.5, 0.4]\n",
    "\n",
    "sns.lmplot(data=pred_df, y=\"Predicted Readbility\",\n",
    "           x=\"Randomness\", hue=\"Tail-Free Sampling\", lowess=True, scatter=False, palette=\"deep\", hue_order=hue_order_lm, legend_out=True)\n",
    "sns.scatterplot(data=nai, y=\"Readability Grade\", x=\"Randomness\", hue=\"Tail-Free\",\n",
    "                 palette=\"deep\", legend=False, hue_order=hue_order_scatter)\n",
    "plt.grid(False)\n",
    "plt.ylabel(\"Readability Grade\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# No longer used...\n",
    "# fig = sm.graphics.plot_partregress_grid(res, exog_idx=[1, 2])\n",
    "# fig.set_size_inches(10, 5)\n",
    "# fig.tight_layout(pad=1.0)\n",
    "\n",
    "# x_labels = [\"Randomness\", \"Tail-Free\"]\n",
    "\n",
    "# for ax, x_label in zip(fig.get_axes(), x_labels):\n",
    "#     ax.set_ylabel(\"Readability\")\n",
    "#     ax.set_xlabel(x_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d63f649",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_rand = nai[\"Nucleus\"].mean()\n",
    "title = \"Impact of TFS on Complexity (plotted for randomness = {}.format(avg_rand))\"\n",
    "\n",
    "sns.lmplot(data=pred_tfs_only_df, y=\"Predicted Readbility\",\n",
    "           x=\"Tail-Free Sampling\", lowess=True, scatter=False)\n",
    "\n",
    "mask = nai[\"Tail-Free\"] < 1\n",
    "sns.scatterplot(data=nai[mask], y=\"Readability Grade\", x=\"Tail-Free\", color = \"blue\")\n",
    "plt.grid(False)\n",
    "plt.ylabel(\"Readability Grade\")\n",
    "plt.xlim(0.35,0.95)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db63433c",
   "metadata": {},
   "source": [
    "### Randomness predicting Glue Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89845458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select best model\n",
    "for pred in predictor_li:\n",
    "    current_pred = pred[1]\n",
    "    current_model_name = pred[0]\n",
    "    cross_val = cross_validate(lin_model, current_pred, nai[\"Glue Index\"],\n",
    "                               scoring=[\"neg_mean_squared_error\", \"r2\"], cv=kf)\n",
    "    neg_mses = cross_val[\"test_neg_mean_squared_error\"]\n",
    "    r_squares = cross_val[\"test_r2\"]\n",
    "    avg_rmse = np.mean((neg_mses*-1)**0.5)\n",
    "    avg_r_sq = np.mean(r_squares)\n",
    "    print(\"Model performance for {} model predicting Glue Index:\".format(\n",
    "        current_model_name))\n",
    "    print(\"r-square: {:.4f}    RMSE: {:.2f}\\n\".format(avg_r_sq, avg_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a1f493",
   "metadata": {},
   "source": [
    "More abysmal model performance - will not bother to investigate further... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6487739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data for people who want to use R Studio or similar\n",
    "\n",
    "nai.to_csv(\"NAI_generation_setting_exp.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 536.4,
   "position": {
    "height": "40px",
    "left": "1120.2px",
    "right": "20px",
    "top": "120px",
    "width": "379px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
